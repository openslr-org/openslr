The AISHELL-4 is a sizable real-recorded Mandarin speech dataset
collected by 8-channel circular microphone array for speech processing
in conference scenarios. The dataset consists of 211 recorded meeting
sessions, each containing 4 to 8 speakers, with a total length of 120
hours. This dataset aims to bridge the advanced research on
multi-speaker processing and the practical application scenario in
three aspects. With real recorded meetings, AISHELL-4 provides
realistic acoustics and rich natural speech characteristics in
conversation such as short pause, speech overlap, quick speaker turn,
noise, etc. Meanwhile, the accurate transcription and speaker voice
activity are provided for each meeting in AISHELL-4. This allows the
researchers to explore different aspects in meeting processing,
ranging from individual tasks such as speech front-end processing,
speech recognition and speaker diarization, to multi-modality modeling
and joint optimization of relevant tasks. We also release a
PyTorch-based training and evaluation framework as a baseline system to
promote reproducible research in this field. The baseline system code
and generated samples are available
<a href="https://github.com/felixfuyihui/AISHELL-4">here</a>.
<p>

You can cite the data
using the following BibTeX entry:
<pre>

@inproceedings{AISHELL-4_2021,
title={AISHELL-4: An Open Source Dataset for Speech Enhancement, Separation, Recognition and Speaker Diarization in Conference Scenario},
author={Yihui Fu, Luyao Cheng, Shubo Lv, Yukai Jv, Yuxiang Kong, Zhuo Chen, Yanxin Hu, Lei Xie, Jian Wu, Hui Bu, Xin Xu, Jun Du, Jingdong Chen},
booktitle={Interspeech},
url={https://arxiv.org/abs/2104.03603},
year={2021}
}
</pre>
